{"cells":[{"cell_type":"code","execution_count":null,"id":"006e099e","metadata":{"colab":{"referenced_widgets":["47af31ba84f44e94954b19b407a26a74","9839796238e4464faca9d54fa28cdb38"]},"id":"006e099e","outputId":"1cae7421-7ccd-4005-84ab-dcf736effe09"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47af31ba84f44e94954b19b407a26a74","version_major":2,"version_minor":0},"text/plain":["HBox(children=(VBox(children=(FileUpload(value=(), accept='.csv', description='Wgraj CSV z danymi'), Dropdown(‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9839796238e4464faca9d54fa28cdb38","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","import io\n","import numpy as np\n","import pandas as pd\n","import plotly.graph_objs as go\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model, Sequential, Model\n","from tensorflow.keras.layers import (\n","    Input, Dense, Dropout, LSTM, Bidirectional, Conv1D, MaxPooling1D,\n","    Flatten, Multiply, Permute, Concatenate, LayerNormalization,\n","    MultiHeadAttention, GlobalAveragePooling1D, RepeatVector, Add\n",")\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from ipywidgets import widgets, VBox, HBox, Output, Label, Button, FileUpload, Dropdown, IntSlider, DatePicker\n","from IPython.display import display, clear_output\n","\n","\n","\n","# --------------------------\n","# Funkcja do wczytania i przygotowania danych\n","def load_and_process_data(file_path_or_buffer):\n","    if isinstance(file_path_or_buffer, str):\n","        df = pd.read_csv(file_path_or_buffer, parse_dates=[\"timestamp\"])\n","    else:\n","        df = pd.read_csv(io.BytesIO(file_path_or_buffer), parse_dates=[\"timestamp\"])\n","    df = df.sort_values(\"timestamp\")\n","    return df\n","\n","# --------------------------\n","# Architektury modeli\n","#stacked LSTM (sunny et.al)\n","def create_model_1(input_shape):\n","    model = Sequential([\n","        LSTM(128, activation='relu', return_sequences=True, input_shape=input_shape),\n","        Dropout(0.3),\n","        LSTM(128, activation='relu'),\n","        Dense(1)\n","    ])\n","    return model\n","\n","\n","#istiake sunny\n","def create_model_2(input_shape):\n","    model = Sequential([\n","        Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),\n","        Dropout(0.3),\n","        Bidirectional(LSTM(64)),\n","        Dense(16, activation='relu'),\n","        Dense(1)\n","    ])\n","    return model\n","\n","\n","\n","\n","def attention_3d_block(inputs, single_attention_vector=False):\n","    time_steps = K.int_shape(inputs)[1]\n","    input_dim = K.int_shape(inputs)[2]\n","    a = Permute((2, 1))(inputs)\n","    a = Dense(time_steps, activation='softmax')(a)\n","    if single_attention_vector:\n","        a = Lambda(lambda x: K.mean(x, axis=1))(a)\n","        a = RepeatVector(input_dim)(a)\n","    a_probs = Permute((2, 1))(a)\n","    output_attention_mul = Multiply()([inputs, a_probs])\n","    return output_attention_mul\n","\n","def create_model_3(input_shape):\n","    inputs = Input(shape=input_shape)\n","\n","    # Warstwa konwolucyjna\n","    x = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)\n","    x = Dropout(0.3)(x)\n","\n","    # Dwukierunkowy LSTM\n","    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n","    x = Dropout(0.3)(x)\n","\n","    # Blok uwagi\n","    x = attention_3d_block(x)\n","\n","    # Sp≈Çaszczamy wynik\n","    x = Flatten()(x)\n","\n","    # Wyj≈õcie modelu\n","    outputs = Dense(1)(x)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","def add_positional_encoding(x):\n","    seq_len = tf.shape(x)[1]\n","    d_model = tf.shape(x)[2]\n","\n","    pos = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n","    i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n","    angle_rates = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    angle_rads = pos * angle_rates\n","\n","    sines = tf.sin(angle_rads[:, 0::2])\n","    cosines = tf.cos(angle_rads[:, 1::2])\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)\n","    pos_encoding = tf.expand_dims(pos_encoding, 0)\n","    return x + pos_encoding\n","\n","def transformer_block(x, head_size, num_heads, ff_dim, dropout=0.1):\n","    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(x, x)\n","    attn_output = Dropout(dropout)(attn_output)\n","    x = Add()([x, attn_output])\n","    x = LayerNormalization(epsilon=1e-6)(x)\n","\n","    ffn = Dense(ff_dim, activation=\"relu\")(x)\n","    ffn = Dense(x.shape[-1])(ffn)\n","    ffn = Dropout(dropout)(ffn)\n","    x = Add()([x, ffn])\n","    x = LayerNormalization(epsilon=1e-6)(x)\n","    return x\n","\n","def create_model_4(input_shape):\n","    inputs = Input(shape=input_shape)\n","\n","    # Dense encoding (jak w PyTorch Linear encoder)\n","    x_encoded = Dense(64)(inputs)\n","\n","    # LSTM blok\n","    x_lstm_pos = tf.keras.layers.Lambda(add_positional_encoding)(x_encoded)\n","    x_lstm = LSTM(32, return_sequences=True)(x_lstm_pos)\n","    x_lstm_last = x_lstm[:, -1, :]  # ostatni krok czasowy\n","\n","    # Transformer blok\n","    x_trans_pos = tf.keras.layers.Lambda(add_positional_encoding)(x_encoded)\n","    x_trans = transformer_block(x_trans_pos, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n","    x_trans_last = x_trans[:, -1, :]  # ostatni krok czasowy\n","\n","    # Po≈ÇƒÖczenie LSTM + Transformer\n","    x_combined = Concatenate()([x_lstm_last, x_trans_last])\n","    x = Dense(64, activation=\"relu\")(x_combined)\n","    x = Dropout(0.2)(x)\n","    outputs = Dense(1)(x)\n","\n","    model = Model(inputs, outputs)\n","    return model\n","\n","\n","\n","architecture_dict = {\n","    \"LSTM 64\": create_model_1,\n","    \"Bidirectional LSTM\": create_model_2,\n","    \"Bidirectional LSTM + Attention\": create_model_3,\n","    \"LSTM + Transformer\": create_model_4,\n","}\n","\n","# --------------------------\n","# UI i widgety\n","output = Output()\n","\n","upload = FileUpload(\n","    accept=\".csv\",\n","    multiple=False,\n","    description=\"Wgraj CSV z danymi\"\n",")\n","\n","choice_asset = Dropdown(\n","    options=[\"BTC\", \"ETH\", \"SP500\", \"AAPL\"],\n","    description=\"Przewiduj:\",\n","    value=\"ETH\"\n",")\n","\n","choice_mode = Dropdown(\n","    options=[\"Trenuj od zera\", \"Fine-tuning istniejƒÖcego modelu\"],\n","    description=\"Tryb uczenia:\",\n","    value=\"Fine-tuning istniejƒÖcego modelu\"\n",")\n","\n","# Usuwamy suwak train_test_split i zastƒôpujemy go DatePickerem\n","train_test_date_picker = DatePicker(\n","    description='Data podzia≈Çu:',\n","    disabled=False\n",")\n","\n","choice_architecture = Dropdown(\n","    options=list(architecture_dict.keys()),\n","    description=\"Architektura:\",\n","    value=\"LSTM 64\"\n",")\n","\n","epochs_slider = IntSlider(\n","    value=15,\n","    min=1,\n","    max=150,\n","    step=1,\n","    description=\"Epoki:\"\n",")\n","\n","button_run = Button(\n","    description=\"Uruchom trening i predykcjƒô\",\n","    button_style='success'\n",")\n","\n","save_model_checkbox = widgets.Checkbox(\n","    value=False,\n","    description='Zapisz model po treningu'\n",")\n","\n","model_name_text = widgets.Text(\n","    value='nowy_model',\n","    description='Nazwa pliku:',\n","    placeholder='np. LSTM_ETH_model',\n","    disabled=False\n",")\n","\n","existing_model_name_text = widgets.Text(\n","    value='./models/LSTM_model.h5',\n","    description='Model do fine-tuningu:',\n","    placeholder='≈õcie≈ºka do modelu .h5',\n","    disabled=False\n",")\n","\n","\n","default_data_path = \"./data/data.csv\"\n","default_model_path = \"./models/LSTM_model.h5\"\n","\n","# --------------------------\n","# Funkcja dopasowania wag Dense z modelu starego do nowego, je≈õli kszta≈Çt pasuje\n","def try_copy_dense_weights(model_new, model_old):\n","    dense_new = model_new.layers[-1]\n","    dense_old = model_old.layers[-1]\n","    weights_old = dense_old.get_weights()\n","    weights_new = dense_new.get_weights()\n","\n","    print(f\"üîç Kszta≈Çt wag starego modelu (Dense): {weights_old[0].shape}, bias: {weights_old[1].shape}\")\n","    print(f\"üîç Kszta≈Çt wag nowego modelu (Dense): {weights_new[0].shape}, bias: {weights_new[1].shape}\")\n","\n","    if weights_old[0].shape == weights_new[0].shape and weights_old[1].shape == weights_new[1].shape:\n","        dense_new.set_weights(weights_old)\n","        print(\"‚ö°Ô∏è Skopiowano wagi Dense z modelu starego.\")\n","    else:\n","        print(\"‚ö†Ô∏è Kszta≈Çt wag Dense nie pasuje. Pomijam kopiowanie wag Dense.\")\n","\n","\n","def try_copy_dense_weights_adapted(model_new, model_old):\n","    dense_new = model_new.layers[-1]\n","    dense_old = model_old.layers[-1]\n","    weights_old = dense_old.get_weights()\n","    weights_new = dense_new.get_weights()\n","\n","    w_old, b_old = weights_old\n","    w_new, b_new = weights_new\n","\n","    print(f\"üîç Stary Dense weights shape: {w_old.shape}, bias: {b_old.shape}\")\n","    print(f\"üîç Nowy Dense weights shape: {w_new.shape}, bias: {b_new.shape}\")\n","\n","    # Dopasuj kszta≈Çt wag wagi przez obciƒôcie lub dope≈Çnienie zerami\n","    w_new_adapted = np.zeros_like(w_new)\n","    b_new_adapted = np.zeros_like(b_new)\n","\n","    min_rows = min(w_old.shape[0], w_new.shape[0])\n","    min_cols = min(w_old.shape[1], w_new.shape[1])\n","    min_bias = min(b_old.shape[0], b_new.shape[0])\n","\n","    # Kopiuj czƒô≈õƒá wsp√≥lnƒÖ wag\n","    w_new_adapted[:min_rows, :min_cols] = w_old[:min_rows, :min_cols]\n","    b_new_adapted[:min_bias] = b_old[:min_bias]\n","\n","    dense_new.set_weights([w_new_adapted, b_new_adapted])\n","    print(\"‚ö°Ô∏è Wagi Dense zosta≈Çy dopasowane i skopiowane.\")\n","\n","\n","# --------------------------\n","# Funkcja wyciƒÖgajƒÖca input_shape z modelu starego (seq_len i features)\n","def get_input_shape_from_model(model_old):\n","    for layer in model_old.layers:\n","        if hasattr(layer, 'input_shape') and layer.input_shape is not None:\n","            # Kszta≈Çt wej≈õcia to (None, seq_len, features)\n","            input_shape = layer.input_shape[1:]  # pomijamy None\n","            return input_shape\n","    return None\n","\n","# --------------------------\n","# Funkcja obs≈ÇugujƒÖca trening i predykcjƒô\n","def on_button_run_clicked(b):\n","    with output:\n","        clear_output()\n","        print(\"Wczytywanie danych... ‚è≥\")\n","        try:\n","            if upload.value:\n","                for filename in upload.value:\n","                    content = upload.value[filename][\"content\"]\n","                    df = load_and_process_data(content)\n","                    print(f\"Wczytano z wgranego pliku: {filename}\")\n","                    break\n","            else:\n","                df = load_and_process_data(default_data_path)\n","                print(f\"Wczytano domy≈õlny plik: {default_data_path}\")\n","        except Exception as e:\n","            print(f\"B≈ÇƒÖd wczytywania danych: {e}\")\n","            return\n","\n","        asset = choice_asset.value\n","        print(f\"Wybrany asset do predykcji: {asset}\")\n","        if asset not in df.columns:\n","            print(f\"Brak kolumny {asset} w danych!\")\n","            return\n","\n","        # Sprawdzamy, czy wybrano datƒô podzia≈Çu\n","        split_date = train_test_date_picker.value\n","        if split_date is None:\n","            print(\"‚ùå Proszƒô wybraƒá datƒô podzia≈Çu danych!\")\n","            return\n","\n","        df_clean = df.dropna(subset=[asset])\n","\n","        # Ustawiamy datƒô podzia≈Çu jako datetime (w razie czego)\n","        split_date = pd.to_datetime(split_date)\n","        print(f\"Data podzia≈Çu na train/test: {split_date.strftime('%Y-%m-%d %H:%M:%S')}\")\n","\n","        # Skalowanie ca≈Çego zbioru przed podzia≈Çem (wa≈ºne)\n","        data_single = df_clean[[asset]]\n","        scaler = MinMaxScaler()\n","        scaled_data = scaler.fit_transform(data_single.values)\n","\n","        # Domy≈õlny seq_len\n","        default_seq_len = 24\n","        seq_len = default_seq_len\n","\n","        # Je≈õli fine-tuning, spr√≥buj pobraƒá seq_len z modelu\n","        if choice_mode.value == \"Fine-tuning istniejƒÖcego modelu\":\n","            try:\n","                model_path = existing_model_name_text.value.strip()\n","                if not os.path.isfile(model_path):\n","                    print(f\"‚ùå Plik modelu '{model_path}' nie istnieje!\")\n","                    return\n","                model_old = load_model(model_path, compile=False)\n","                print(f\"Wczytano model do fine-tuningu z {model_path}\")\n","                input_shape_old = get_input_shape_from_model(model_old)\n","                if input_shape_old is not None:\n","                    seq_len = input_shape_old[0]\n","                    features_old = input_shape_old[1]\n","                    print(f\"Input shape z modelu starego: {input_shape_old} (seq_len={seq_len}, features={features_old})\")\n","                else:\n","                    print(\"Nie uda≈Ço siƒô wyciƒÖgnƒÖƒá input_shape ze starego modelu, u≈ºywam domy≈õlnego seq_len.\")\n","                    seq_len = default_seq_len\n","            except Exception as e:\n","                print(f\"B≈ÇƒÖd przy wczytywaniu starego modelu: {e}\")\n","                seq_len = default_seq_len\n","\n","        # Tworzymy sekwencje X, y dla ca≈Çego zbioru\n","        X_all, y_all, timestamps_all = [], [], []\n","        for i in range(len(scaled_data) - seq_len):\n","            X_all.append(scaled_data[i:i+seq_len])\n","            y_all.append(scaled_data[i+seq_len, 0])\n","            timestamps_all.append(df_clean[\"timestamp\"].iloc[i + seq_len])\n","\n","        X_all = np.array(X_all)\n","        y_all = np.array(y_all)\n","        timestamps_all = pd.Series(timestamps_all)\n","\n","        # Podzia≈Ç na train/test wg daty - timestampy w timestamps_all to timestampy odpowiadajƒÖce y\n","        mask_train = timestamps_all <= split_date\n","        mask_test = timestamps_all > split_date\n","\n","        X_train = X_all[mask_train.values]\n","        y_train = y_all[mask_train.values]\n","        X_test = X_all[mask_test.values]\n","        y_test = y_all[mask_test.values]\n","        timestamps_test = timestamps_all[mask_test.values]\n","\n","        print(f\"Dane podzielone na trening ({len(X_train)}) i test ({len(X_test)})\")\n","\n","        if len(X_train) == 0 or len(X_test) == 0:\n","            print(\"‚ùå Zbyt ma≈Ço danych w zbiorze treningowym lub testowym po podziale datƒÖ. Proszƒô wybraƒá innƒÖ datƒô.\")\n","            return\n","\n","        input_shape_new = (seq_len, 1)  # mamy jeden feature\n","\n","        # Tworzymy nowy model i kopiujemy wagi Dense je≈õli mo≈ºliwe\n","        if choice_mode.value == \"Fine-tuning istniejƒÖcego modelu\":\n","            try:\n","                create_fn = architecture_dict[choice_architecture.value]\n","                model = create_fn(input_shape_new)\n","                try_copy_dense_weights_adapted(model, model_old)\n","            except Exception as e:\n","                print(f\"B≈ÇƒÖd przy tworzeniu nowego modelu lub kopiowaniu wag: {e}\")\n","                print(\"Tworzƒô model od zera z domy≈õlnym shape.\")\n","                create_fn = architecture_dict[choice_architecture.value]\n","                model = create_fn(input_shape_new)\n","        else:\n","            print(\"Tworzenie modelu od zera z domy≈õlnym shape...\")\n","            create_fn = architecture_dict[choice_architecture.value]\n","            model = create_fn(input_shape_new)\n","\n","        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n","\n","        early_stopping = EarlyStopping(monitor=\"val_loss\", patience=12)\n","\n","        print(\"Start treningu...\")\n","        history = model.fit(\n","            X_train, y_train,\n","            validation_split=0.1,\n","            epochs=epochs_slider.value,\n","            batch_size=32,\n","            callbacks=[early_stopping],\n","            verbose=1\n","        )\n","\n","        if save_model_checkbox.value:\n","            model.save(f\"{model_name_text.value}.h5\")\n","            print(f\"Model zapisany jako {model_name_text.value}.h5\")\n","\n","        print(\"Robiƒô predykcje na zbiorze testowym...\")\n","        pred_test_scaled = model.predict(X_test)\n","\n","        # Odskalowanie do oryginalnych warto≈õci\n","        y_test_orig = scaler.inverse_transform(y_test.reshape(-1,1)).flatten()\n","        pred_test_orig = scaler.inverse_transform(pred_test_scaled).flatten()\n","\n","\n","\n","        # Obliczenie miar regresji\n","        mse = mean_squared_error(y_test_orig, pred_test_orig)\n","        rmse = np.sqrt(mse)\n","        mae = mean_absolute_error(y_test_orig, pred_test_orig)\n","        mape = np.mean(np.abs((y_test_orig - pred_test_orig) / y_test_orig)) * 100\n","        r2 = r2_score(y_test_orig, pred_test_orig)\n","\n","        # Wy≈õwietlenie metryk\n","        print(\"\\nüìä Miary regresji:\")\n","        print(f\"‚û°Ô∏è  MSE  (Mean Squared Error): {mse:.4f}\")\n","        print(f\"‚û°Ô∏è  RMSE (Root Mean Squared Error): {rmse:.4f}\")\n","        print(f\"‚û°Ô∏è  MAE  (Mean Absolute Error): {mae:.4f}\")\n","        print(f\"‚û°Ô∏è  MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n","        print(f\"‚û°Ô∏è  R¬≤   (R-squared): {r2:.4f}\")\n","\n","        # Wykres predykcji i rzeczywistych warto≈õci z osi czasu z timestamps_test\n","        fig = go.Figure()\n","        fig.add_trace(go.Scatter(\n","            x=timestamps_test,\n","            y=y_test_orig,\n","            mode='lines',\n","            name='Rzeczywiste'\n","        ))\n","        fig.add_trace(go.Scatter(\n","            x=timestamps_test,\n","            y=pred_test_orig,\n","            mode='lines',\n","            name='Predykcja'\n","        ))\n","        fig.update_layout(\n","            title=f\"Predykcja na zbiorze testowym ({asset})\",\n","            xaxis_title=\"Data\",\n","            yaxis_title=\"Warto≈õƒá\",\n","            hovermode='x unified'\n","        )\n","        fig.show()\n","\n","# --------------------------\n","# Podpinanie eventu do przycisku\n","button_run.on_click(on_button_run_clicked)\n","\n","# --------------------------\n","# Uk≈Çad widget√≥w\n","ui_left = VBox([\n","    upload,\n","    choice_asset,\n","    train_test_date_picker,\n","    choice_mode,\n","    existing_model_name_text,\n","    choice_architecture,\n","    epochs_slider,\n","    save_model_checkbox,\n","    model_name_text,\n","    button_run\n","])\n","\n","ui = HBox([ui_left])\n","\n","display(ui, output)\n"]},{"cell_type":"code","execution_count":null,"id":"27e0b059","metadata":{"id":"27e0b059"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import plotly.graph_objs as go\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from tensorflow.keras.models import load_model\n","from ipywidgets import widgets, VBox, DatePicker, Text, Button, Dropdown, Output\n","from IPython.display import display, clear_output\n","\n","# Funkcja wczytuje dane i sortuje je po dacie\n","def load_and_prepare_data(path='./data/data.csv'):\n","    df = pd.read_csv(path, parse_dates=['timestamp'])\n","    df = df.sort_values('timestamp')\n","    return df\n","\n","# Pobiera kszta≈Çt wej≈õcia modelu (potrzebny do przygotowania sekwencji)\n","def get_input_shape_from_model(model):\n","    try:\n","        shape = model.input_shape\n","        if isinstance(shape, list):\n","            shape = shape[0]\n","        return shape[1], shape[2]\n","    except Exception:\n","        return None\n","\n","# Tworzy interfejs u≈ºytkownika do wczytania modelu i uruchomienia predykcji\n","def create_prediction_ui():\n","    output = Output()\n","\n","    model_file_text = Text(\n","        value='./models/ETH_100_3.h5',\n","        description='Model .h5:',\n","        layout=widgets.Layout(width='60%')\n","    )\n","\n","    date_picker = DatePicker(\n","        description='Data testu od:',\n","        disabled=False\n","    )\n","\n","    button_run = Button(\n","        description=\"Uruchom predykcjƒô\",\n","        button_style='success'\n","    )\n","\n","    asset_dropdown = Dropdown(\n","        options=[],\n","        description='Cecha:',\n","        disabled=False\n","    )\n","\n","    # Wczytanie listy dostƒôpnych cech (kolumn) z pliku danych\n","    def update_asset_options():\n","        try:\n","            df = load_and_prepare_data()\n","            cols = [col for col in df.columns if col != 'timestamp']\n","            asset_dropdown.options = cols\n","            if cols:\n","                asset_dropdown.value = cols[0]\n","        except Exception:\n","            asset_dropdown.options = []\n","\n","    update_asset_options()\n","\n","    # G≈Ç√≥wna funkcja uruchamiana po klikniƒôciu przycisku\n","    def on_button_run_clicked(b):\n","        with output:\n","            clear_output()\n","            print(\"Wczytywanie modelu i danych...\")\n","            model_path = model_file_text.value.strip()\n","            if not model_path:\n","                print(\"‚ùå Podaj ≈õcie≈ºkƒô do pliku modelu!\")\n","                return\n","\n","            # Pr√≥ba wczytania modelu\n","            try:\n","                model = load_model(model_path, compile=False)\n","                print(f\"Wczytano model z: {model_path}\")\n","            except Exception as e:\n","                print(f\"‚ùå B≈ÇƒÖd wczytywania modelu: {e}\")\n","                return\n","\n","            # Pr√≥ba wczytania danych\n","            try:\n","                df = load_and_prepare_data()\n","                print(\"Wczytano dane z './data/data.csv'\")\n","            except Exception as e:\n","                print(f\"‚ùå B≈ÇƒÖd wczytywania danych: {e}\")\n","                return\n","\n","            asset = asset_dropdown.value\n","            if asset is None:\n","                print(\"‚ùå Proszƒô wybraƒá cechƒô do predykcji!\")\n","                return\n","\n","            split_date = date_picker.value\n","            if split_date is None:\n","                print(\"‚ùå Proszƒô wybraƒá datƒô testowƒÖ!\")\n","                return\n","            split_date = pd.to_datetime(split_date)\n","\n","            # Przygotowanie danych: czyszczenie i skalowanie\n","            df_clean = df.dropna(subset=[asset])\n","            scaler = MinMaxScaler()\n","            scaled_data = scaler.fit_transform(df_clean[[asset]].values)\n","\n","            # Sprawdzenie kszta≈Çtu wej≈õciowego modelu\n","            input_shape = get_input_shape_from_model(model)\n","            if input_shape is None:\n","                print(\"‚ùå Nie uda≈Ço siƒô pobraƒá input_shape!\")\n","                return\n","\n","            seq_len, features = input_shape\n","\n","            if len(scaled_data) <= seq_len:\n","                print(f\"‚ùå Za ma≈Ço danych ({len(scaled_data)}) na d≈Çugo≈õƒá sekwencji ({seq_len})\")\n","                return\n","\n","            # Tworzenie sekwencji dla predykcji\n","            X_all, y_all, timestamps_all = [], [], []\n","            for i in range(len(scaled_data) - seq_len):\n","                seq = scaled_data[i:i + seq_len]\n","                if features == 1:\n","                    X_all.append(seq)\n","                else:\n","                    # Dopasowanie liczby cech je≈õli model oczekuje wiƒôcej ni≈º 1 feature\n","                    repeated = np.repeat(seq, features, axis=1)[:, :features]\n","                    X_all.append(repeated)\n","                y_all.append(scaled_data[i + seq_len, 0])\n","                timestamps_all.append(df_clean['timestamp'].iloc[i + seq_len])\n","\n","            X_all = np.array(X_all)\n","            y_all = np.array(y_all)\n","            timestamps_all = pd.Series(timestamps_all)\n","\n","            # Podzia≈Ç na zbi√≥r testowy wed≈Çug wybranej daty\n","            mask_test = timestamps_all >= split_date\n","            X_test = X_all[mask_test.values]\n","            y_test = y_all[mask_test.values]\n","            timestamps_test = timestamps_all[mask_test.values]\n","\n","            if len(X_test) == 0:\n","                print(\"‚ùå Brak danych testowych po tej dacie.\")\n","                return\n","\n","            print(f\"Zbi√≥r testowy: {len(X_test)} pr√≥bek. Robiƒô predykcjƒô...\")\n","            pred_test_scaled = model.predict(X_test)\n","\n","            # Odwr√≥cenie skalowania do oryginalnych warto≈õci\n","            y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n","            pred_test_orig = scaler.inverse_transform(pred_test_scaled).flatten()\n","\n","            # Obliczenie metryk jako≈õci predykcji\n","            mse = mean_squared_error(y_test_orig, pred_test_orig)\n","            rmse = np.sqrt(mse)\n","            mae = mean_absolute_error(y_test_orig, pred_test_orig)\n","            mape = np.mean(np.abs((y_test_orig - pred_test_orig) / y_test_orig)) * 100\n","            r2 = r2_score(y_test_orig, pred_test_orig)\n","\n","            print(\"\\nüìä Miary regresji:\")\n","            print(f\"MSE:  {mse:.4f}\")\n","            print(f\"RMSE: {rmse:.4f}\")\n","            print(f\"MAE:  {mae:.4f}\")\n","            print(f\"MAPE: {mape:.2f}%\")\n","            print(f\"R¬≤:   {r2:.4f}\")\n","\n","            # Rysowanie wykresu wynik√≥w\n","            fig = go.Figure()\n","            fig.add_trace(go.Scatter(x=timestamps_test, y=y_test_orig, mode='lines', name='Rzeczywiste'))\n","            fig.add_trace(go.Scatter(x=timestamps_test, y=pred_test_orig, mode='lines', name='Predykcja'))\n","            fig.update_layout(\n","                title=f\"Predykcja od {split_date.date()}\",\n","                xaxis_title=\"Data\",\n","                yaxis_title=\"Warto≈õƒá\",\n","                hovermode='x unified'\n","            )\n","            fig.show()\n","\n","    button_run.on_click(on_button_run_clicked)\n","\n","    ui = VBox([model_file_text, asset_dropdown, date_picker, button_run, output])\n","    display(ui)\n"]},{"cell_type":"code","execution_count":null,"id":"23694b0c","metadata":{"colab":{"referenced_widgets":["2423585ce5f0429d82cb8f0204e8fe3a"]},"id":"23694b0c","outputId":"48180e29-26a4-424f-eaa2-659e222aa042"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2423585ce5f0429d82cb8f0204e8fe3a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/LSTM_model.h5', description='Model .h5:', layout=Layout(width='60%')), Dro‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()\n"]},{"cell_type":"code","execution_count":null,"id":"b010bf7d","metadata":{"colab":{"referenced_widgets":["7bf412973bd943ad9c3b46c5fce25d0e"]},"id":"b010bf7d","outputId":"e8330554-408a-41cb-ae2a-68f10192a062"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bf412973bd943ad9c3b46c5fce25d0e","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()\n"]},{"cell_type":"code","execution_count":null,"id":"6aea744b","metadata":{"colab":{"referenced_widgets":["27e2bddc35764624bdd36d66060d566f"]},"id":"6aea744b","outputId":"9d0bd687-8a9e-48e4-f6cb-d9b28a9395d8"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27e2bddc35764624bdd36d66060d566f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()\n"]},{"cell_type":"code","execution_count":null,"id":"b9b76ce6","metadata":{"colab":{"referenced_widgets":["84137f625ecb4685896f586b59c9458c"]},"id":"b9b76ce6","outputId":"a08fcd69-e1c0-47d9-eb96-b99ca81971e4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84137f625ecb4685896f586b59c9458c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()\n"]},{"cell_type":"code","execution_count":null,"id":"18403c7e","metadata":{"colab":{"referenced_widgets":["df3c44930fe2484ca87ef6e91775bee8"]},"id":"18403c7e","outputId":"e697fe40-a731-4f18-c22e-4d574a07e05f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df3c44930fe2484ca87ef6e91775bee8","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()"]},{"cell_type":"code","execution_count":null,"id":"70604a8b","metadata":{"colab":{"referenced_widgets":["ad4b3e1c9fdf4b4c8781d36948c7effc"]},"id":"70604a8b","outputId":"995f9a1f-43ec-437a-adf8-68d0429fc9b5"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad4b3e1c9fdf4b4c8781d36948c7effc","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()"]},{"cell_type":"code","execution_count":null,"id":"30c371f7","metadata":{"colab":{"referenced_widgets":["f27818ff67e04377a959b11496de4bb8"]},"id":"30c371f7","outputId":"8b1d7da3-d452-4ca0-8f74-e682c69e759f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f27818ff67e04377a959b11496de4bb8","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Text(value='./models/ETH_100_3.h5', description='Model .h5:', layout=Layout(width='60%')), Drop‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["create_prediction_ui()"]}],"metadata":{"kernelspec":{"display_name":"lstm-proj","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}