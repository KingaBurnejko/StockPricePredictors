{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518398d0",
   "metadata": {},
   "source": [
    "# Wyznaczanie optymalnych p i q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f61162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3401d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, return_scaling=100):\n",
    "\n",
    "    df = pd.read_csv(dataset, parse_dates=[\"timestamp\"])\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    df['returns'] = return_scaling * np.log(df['close'] / df['close'].shift(1))\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_garch(p, q, train_returns, test_returns):\n",
    "\n",
    "    print(f\"Testing GARCH({p},{q})...\")\n",
    "    rolling_predictions = []\n",
    "    history = train_returns.copy()\n",
    "\n",
    "    try:\n",
    "        for i in range(len(test_returns)):\n",
    "            model = arch_model(history, vol='GARCH', p=p, q=q)\n",
    "            model_fit = model.fit(disp='off', update_freq=0)\n",
    "            forecast = model_fit.forecast(horizon=1)\n",
    "            rolling_predictions.append(np.sqrt(forecast.variance.values[-1, 0]))\n",
    "            history = pd.concat([history, test_returns.iloc[i:i+1]])\n",
    "\n",
    "        actual = np.abs(test_returns)\n",
    "        predicted = np.array(rolling_predictions)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        mae = mean_absolute_error(actual, predicted)\n",
    "        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "        final_model = arch_model(train_returns, vol='GARCH', p=p, q=q)\n",
    "        final_fit = final_model.fit(disp='off')\n",
    "        aic = final_fit.aic\n",
    "        bic = final_fit.bic\n",
    "\n",
    "        return {'p': p, 'q': q, 'AIC': aic, 'BIC': bic, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for ({p},{q}): {e}\")\n",
    "        return {'p': p, 'q': q, 'AIC': np.inf, 'BIC': np.inf, 'RMSE': np.inf, 'MAE': np.inf, 'MAPE': np.inf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_garch(train_returns, test_returns, max_p, max_q, dataset_name):\n",
    "\n",
    "    p_values = range(1, max_p+1)\n",
    "    q_values = range(1, max_q+1)\n",
    "\n",
    "    results = []\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            result = evaluate_garch(p, q, train_returns, test_returns)\n",
    "            results.append(result)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by='RMSE')\n",
    "    print(\"\\n** Model comparison results:\")\n",
    "    print(results_df[['p', 'q', 'RMSE']])\n",
    "\n",
    "    results_file=f'{dataset_name}_garch_results.csv'\n",
    "\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f\"Results saved: {results_file}\")\n",
    "\n",
    "    best = results_df.iloc[0]\n",
    "    p_best, q_best = int(best['p']), int(best['q'])\n",
    "    print(f\"\\nBest GARCH model for {dataset_name}: ({p_best},{q_best})\\nRMSE = {best['RMSE']:.4f}\\nMAE = {best['MAE']:.4f}\\nMAPE = {best['MAPE']:.2f}%\")\n",
    "\n",
    "    return (p_best, q_best), results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f80fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(test_data, predictions, model_info):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test_data.index, np.abs(test_data['returns']),\n",
    "             label=\"Actual\", alpha=0.7)\n",
    "    plt.plot(test_data.index, predictions, linestyle=\"--\",\n",
    "             label=f\"GARCH({model_info['p']},{model_info['q']}) forecast\",\n",
    "             color='orange')\n",
    "    plt.title(f\"Volatility comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, train_end_date, max_p, max_q):\n",
    "    dataset_name = dataset.split('_')[0].lower()\n",
    "    df = load_data(dataset)\n",
    "    train = df[df.index < train_end_date]\n",
    "    test = df[df.index >= train_end_date].copy()\n",
    "    test_returns = test['returns']\n",
    "    \n",
    "    (p_best, q_best), results_df = find_best_garch(\n",
    "        train['returns'], test_returns, max_p, max_q, dataset_name)\n",
    "    \n",
    "    final_model = arch_model(train['returns'], vol='GARCH', p=p_best, q=q_best)\n",
    "    final_fit = final_model.fit(disp='off')\n",
    "    \n",
    "    predictions = []\n",
    "    history = train['returns'].copy()\n",
    "\n",
    "    for i in range(len(test_returns)):\n",
    "        model = arch_model(history, vol='GARCH', p=p_best, q=q_best)\n",
    "        model_fit = model.fit(disp='off', update_freq=0)\n",
    "        forecast = model_fit.forecast(horizon=1)\n",
    "        predictions.append(np.sqrt(forecast.variance.values[-1, 0]))\n",
    "        history = pd.concat([history, test_returns.iloc[i:i+1]])\n",
    "        \n",
    "    test['predicted_volatility'] = predictions\n",
    "\n",
    "    best_model_info = results_df.iloc[0].to_dict()\n",
    "    comparison_plot(test, predictions, best_model_info)\n",
    "    \n",
    "    save_model(final_fit, f'{dataset_name}_garch_model_p{p_best}_q{q_best}.pkl')    \n",
    "\n",
    "    return final_fit, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4aa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"ETH_data.csv\", \"SPY_data.csv\", \"AAPL_data.csv\", \"BTC_data.csv\"]\n",
    "train_end_date = \"2025-01-01\"\n",
    "max_p=5\n",
    "max_q=5\n",
    "\n",
    "for dataset in datasets:\n",
    "    final_model, test_results = main(dataset, train_end_date, max_p, max_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73802d",
   "metadata": {},
   "source": [
    "# Prognozowanie cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49712baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, parse_dates=['timestamp'])\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    df['returns'] = 100 * np.log(df['close'] / df['close'].shift(1))\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b083e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast(df, train_end_date, garch_p=1, garch_q=1, arima_p=1, arima_d=1, arima_q=1):\n",
    "    train_df = df[df.index < train_end_date].copy()\n",
    "    test_df = df[df.index >= train_end_date].copy()\n",
    "\n",
    "    arima = ARIMA(train_df['close'], order=(arima_p, arima_d, arima_q)).fit(method_kwargs={\"maxiter\": 500})\n",
    "    \n",
    "    residuals = arima.resid\n",
    "    garch = arch_model(residuals, vol='GARCH', p=garch_p, q=garch_q).fit(disp='off', update_freq=5)\n",
    "    \n",
    "    preds = []\n",
    "    actuals = []\n",
    "    dates = []\n",
    "\n",
    "    current_series = train_df['close'].tolist()\n",
    "    \n",
    "    for date in test_df.index:\n",
    "        try:\n",
    "            arima_forecast = arima.forecast(steps=1).iloc[0]\n",
    "            \n",
    "            garch_vol = np.sqrt(garch.forecast(horizon=1).variance.iloc[-1,0])\n",
    "            \n",
    "            combined_forecast = arima_forecast + np.random.normal(0, garch_vol)\n",
    "            \n",
    "            preds.append(combined_forecast)\n",
    "            actuals.append(df.loc[date, 'close'])\n",
    "            dates.append(date)\n",
    "            \n",
    "            current_series.append(combined_forecast)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error for date {date}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'actual': actuals,\n",
    "        'predicted': preds\n",
    "    }).set_index('date')\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_df, horizon_days):\n",
    "    if len(pred_df) < horizon_days:\n",
    "        return None\n",
    "    sub = pred_df.iloc[:horizon_days]\n",
    "    actual = sub['actual'].values\n",
    "    predicted = sub['predicted'].values\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    return predicted, mape, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91adc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(pred_df, name):\n",
    "    if name.lower() == 'aapl':\n",
    "        range_map = {\n",
    "            \"1_tydzien\": 16*7,\n",
    "            \"2_tygodnie\": 16*14,\n",
    "            \"3_tygodnie\": 16*21,\n",
    "            \"1_miesiac\": 320,\n",
    "            \"2_miesiace\": 640,\n",
    "            \"3_miesiace\": len(pred_df)\n",
    "        }\n",
    "    elif name.lower() in ['btc', 'eth']:\n",
    "        range_map = {\n",
    "            \"1_tydzien\": 24*7,\n",
    "            \"2_tygodnie\": 24*14,\n",
    "            \"3_tygodnie\": 24*21,\n",
    "            \"1_miesiac\": 744,\n",
    "            \"2_miesiace\": 2*744,\n",
    "            \"3_miesiace\": len(pred_df)\n",
    "        }\n",
    "    elif name.lower() == 'spy':\n",
    "        range_map = {\n",
    "            \"1_tydzien\": 17*7,\n",
    "            \"2_tygodnie\": 17*14,\n",
    "            \"3_tygodnie\": 17*21,\n",
    "            \"1_miesiac\": 340,\n",
    "            \"2_miesiace\": 2*340,\n",
    "            \"3_miesiace\": len(pred_df)\n",
    "        }\n",
    "\n",
    "    range_name_map = {\n",
    "        \"1_tydzien\": \"tyg\",\n",
    "        \"2_tygodnie\": \"2tyg\",\n",
    "        \"3_tygodnie\": \"3tyg\",\n",
    "        \"1_miesiac\": \"msc\",\n",
    "        \"2_miesiace\": \"2msc\",\n",
    "        \"3_miesiace\": \"3msc\"\n",
    "    }\n",
    "\n",
    "    range_name_map = {\n",
    "        \"1_tydzien\": \"tyg\",\n",
    "        \"2_tygodnie\": \"2tyg\",\n",
    "        \"3_tygodnie\": \"3tyg\",\n",
    "        \"1_miesiac\": \"msc\",\n",
    "        \"2_miesiace\": \"2msc\",\n",
    "        \"3_miesiace\": \"3msc\"\n",
    "    }\n",
    "\n",
    "    output_folder = f\"wyniki_predykcji/{name.lower()}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for range_name, days in range_map.items():\n",
    "        result = calculate_metrics(pred_df, days)\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        preds, mape, r2 = result\n",
    "        okres = range_name_map[range_name]\n",
    "        podmiot = name.lower()\n",
    "\n",
    "        preds_filename = f\"{podmiot}_{okres}_GARCH.txt\"\n",
    "        preds_filepath = os.path.join(output_folder, preds_filename)\n",
    "        np.savetxt(preds_filepath, preds, fmt=\"%.6f\")\n",
    "\n",
    "        metrics_filename = f\"{podmiot}_{okres}_GARCH_metrics.txt\"\n",
    "        metrics_filepath = os.path.join(output_folder, metrics_filename)\n",
    "        with open(metrics_filepath, \"w\") as f:\n",
    "            f.write(f\"{mape:.4f}\\n\")\n",
    "            f.write(f\"{r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_params = {\n",
    "    'AAPL': {'garch_p': 2, 'garch_q': 3},\n",
    "    'SPY': {'garch_p': 4, 'garch_q': 5},\n",
    "    'ETH': {'garch_p': 4, 'garch_q': 2},\n",
    "    'BTC': {'garch_p': 4, 'garch_q': 4}\n",
    "}\n",
    "\n",
    "for asset, params in assets_params.items():\n",
    "    fname = f\"{asset}_data.csv\"\n",
    "    try:\n",
    "        data = load_data(fname)\n",
    "        pred_df = calculate_forecast(data, train_end_date=\"2025-01-01\", \n",
    "                                    garch_p=params['garch_p'], \n",
    "                                    garch_q=params['garch_q'])\n",
    "        save_results(pred_df, asset)\n",
    "        print(f\"Przetworzono {asset} pomyślnie\")\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas przetwarzania {asset}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
